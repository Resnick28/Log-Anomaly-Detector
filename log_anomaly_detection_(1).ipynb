{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import math\n",
        "import random\n",
        "from keras.utils import pad_sequences\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-12-20T07:09:49.822562Z",
          "iopub.execute_input": "2022-12-20T07:09:49.823045Z",
          "iopub.status.idle": "2022-12-20T07:09:49.845644Z",
          "shell.execute_reply.started": "2022-12-20T07:09:49.823012Z",
          "shell.execute_reply": "2022-12-20T07:09:49.844313Z"
        },
        "trusted": true,
        "id": "RJRm3Z0ZX9UP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOZRI5KkYCyp",
        "outputId": "c3319142-67c0-4635-d817-e597c2399f0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/train.json', typ = 'series')\n",
        "\n",
        "index = df.keys()\n",
        "log_event=[] #store log information\n",
        "train = [] #store 1 or 0 for anomaly\n",
        "all_log_event = {} #all_log_event store all usefull information of log with its classification\n",
        "\n",
        "#### Extracting usefull information of log ########\n",
        "j = 0\n",
        "for i in index:\n",
        "    temp='{}'.format(j)\n",
        "    for k in i.split()[8:]:\n",
        "        if(any(ch.isdigit() for ch in k) == False):\n",
        "            temp+=k\n",
        "            temp+=\" \"\n",
        "    all_log_event[temp]=df[i]\n",
        "    j+=1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T07:09:49.848044Z",
          "iopub.execute_input": "2022-12-20T07:09:49.849100Z",
          "iopub.status.idle": "2022-12-20T07:11:10.759643Z",
          "shell.execute_reply.started": "2022-12-20T07:09:49.849062Z",
          "shell.execute_reply": "2022-12-20T07:11:10.757984Z"
        },
        "trusted": true,
        "id": "O0PG7DQgX9UT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### getting random data from all_log_event ########\n",
        "N = 1000000\n",
        "ana = [i for i in all_log_event if all_log_event[i] == 'abnormal']\n",
        "nor = [i for i in all_log_event if all_log_event[i] == 'normal']\n",
        "log_event = ana\n",
        "log_event.extend(random.sample( list(all_log_event),N-69692))#N data to train W matrix"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T07:11:10.761806Z",
          "iopub.execute_input": "2022-12-20T07:11:10.762687Z",
          "iopub.status.idle": "2022-12-20T07:11:15.542609Z",
          "shell.execute_reply.started": "2022-12-20T07:11:10.762643Z",
          "shell.execute_reply": "2022-12-20T07:11:15.541263Z"
        },
        "trusted": true,
        "id": "2tsZOoT4X9UU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(log_event))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T07:11:15.544319Z",
          "iopub.execute_input": "2022-12-20T07:11:15.544692Z",
          "iopub.status.idle": "2022-12-20T07:11:15.550977Z",
          "shell.execute_reply.started": "2022-12-20T07:11:15.544658Z",
          "shell.execute_reply": "2022-12-20T07:11:15.550047Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmbvnP5HX9UU",
        "outputId": "0ffd19d4-490a-47b3-8ad6-2521f01f9dfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr = bool(0)#anomaly or normal for every log data\n",
        "for i in log_event:\n",
        "    if(all_log_event[i] == 'normal'):\n",
        "        tr = 0;\n",
        "    else:\n",
        "        tr = 1;\n",
        "    train.append(tr)\n",
        "    tr = bool(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T07:11:15.553188Z",
          "iopub.execute_input": "2022-12-20T07:11:15.554179Z",
          "iopub.status.idle": "2022-12-20T07:11:16.836888Z",
          "shell.execute_reply.started": "2022-12-20T07:11:15.554128Z",
          "shell.execute_reply": "2022-12-20T07:11:16.835597Z"
        },
        "trusted": true,
        "id": "cjovvAXaX9UU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########Preprocessing on log_event############\n",
        "#storing log_event into my_data\n",
        "my_data = []\n",
        "for i in log_event:\n",
        "    my_data.append(i)\n",
        "vectorize = Tokenizer(filters='1234567890')\n",
        "vectorize.fit_on_texts(my_data)#creating dictionary of unique words\n",
        "my_data = vectorize.texts_to_sequences(my_data)#replacing words with numbers\n",
        "total_vocab = sum(len(s) for s in my_data)\n",
        "word_count = len(vectorize.word_index) + 1\n",
        "print(word_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T07:11:16.838386Z",
          "iopub.execute_input": "2022-12-20T07:11:16.839778Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2Rz1ltSX9UV",
        "outputId": "82ce2f6a-69ca-4271-c54d-af3b6f538efc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(my_data)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qjVKfO_mX9UW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 10\n",
        "dim_word = int(word_count/2)\n",
        "Tf = []\n",
        "W = []\n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "model.add(Dense(dim_word, activation='relu'))\n",
        "model.add(Dense(2*window_size, activation='relu'))\n",
        "model.compile(loss='MeanSquaredError', optimizer='adam')\n",
        "coded = vectorize.word_index\n",
        "for i in range(1,1+len(coded)):\n",
        "    tftemp=0\n",
        "    inputt = []\n",
        "    outputt = []\n",
        "    for k in my_data:\n",
        "        if(i in k):\n",
        "            tftemp+=1\n",
        "            text_len = len(k)\n",
        "            context_word = []\n",
        "            idx = k.index(i)#index of target word\n",
        "            #getting things ready for context\n",
        "            begin = idx - window_size\n",
        "            end = idx + window_size + 1\n",
        "            context_word.append([k[m] for m in range(begin, end) if (0 <= m < text_len and m != idx)])\n",
        "            contextual = pad_sequences(context_word, maxlen = 2*window_size)\n",
        "            #done\n",
        "            #making input as a vector\n",
        "            inp = pad_sequences([[i,],])\n",
        "            #only add new values to training dataset\n",
        "            flag=0\n",
        "            for j in outputt:\n",
        "                if (contextual == j).all():\n",
        "                    flag=1\n",
        "            if(flag==0):\n",
        "                outputt.append(contextual)\n",
        "                inputt.append(inp)\n",
        "    Tf.append(tftemp)\n",
        "    #training for given words using training set\n",
        "    for j in range(len(inputt)):\n",
        "        # print(\"hello\")\n",
        "        model.fit(inputt[j],outputt[j],epochs=2,verbose = 0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VfThGCWnX9UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making other neural network to calculate features of a word (value of hidden layer)\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(1, activation='softmax',weights=model.layers[0].get_weights()))\n",
        "model2.add(Dense(dim_word, activation='softmax'))\n",
        "###Calculating W Matrix\n",
        "W.append(model2.predict([[inp2,],]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "jEUGRlAZX9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hudk04JlX9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.array(W).shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pSDT7y-gX9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########--Calculation of Tf-Idf--###########\n",
        "Tf = [i/word_count for i in Tf]\n",
        "Idf = []\n",
        "for i in range(1,1+len(coded)):\n",
        "    idftemp = 0\n",
        "    for j in my_data:\n",
        "        if(i in j):\n",
        "            idftemp+=1\n",
        "    Idf.append(idftemp)\n",
        "Idf = [np.log((N+1)/idf) for idf in Idf]\n",
        "TfIdf = list(np.array(Tf)*np.array(Idf))"
      ],
      "metadata": {
        "trusted": true,
        "id": "GKZ2FHATX9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########--Calculate T.matrix--##########\n",
        "T =[]\n",
        "for i in my_data[:100000]:\n",
        "    temp = []\n",
        "    for j in range(1,1+len(coded)):\n",
        "        if(j in i):\n",
        "            temp.append(TfIdf[j-1])\n",
        "        else:\n",
        "            temp.append(0)\n",
        "    T.append(temp)"
      ],
      "metadata": {
        "trusted": true,
        "id": "E0yoQOUYX9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(T.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "HSB3MdxEX9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(W)\n",
        "newW=[]\n",
        "for i in W:\n",
        "    newW.append(i[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "MiZxR590X9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(W)"
      ],
      "metadata": {
        "trusted": true,
        "id": "etHRa55fX9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########Calculating E matrix############\n",
        "E = np.matmul(np.array(T),np.array(newW))"
      ],
      "metadata": {
        "trusted": true,
        "id": "W9PzJtqSX9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))"
      ],
      "metadata": {
        "trusted": true,
        "id": "LMSY5qgvX9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########Final Neural Network#########\n",
        "final_model = Sequential()\n",
        "final_model.add(Dense(dim_word, activation='relu'))\n",
        "# final_model.add(Dense(100, activation='relu'))\n",
        "final_model.add(Dense(1, activation='sigmoid'))\n",
        "final_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "ind =0 \n",
        "for inp in (E):\n",
        "    temp = []\n",
        "    for i in inp:\n",
        "        temp.append(float(i))\n",
        "    final_model.fit([temp],[[int(train[ind])]], verbose = 0)\n",
        "    ind+=1"
      ],
      "metadata": {
        "_kg_hide-output": false,
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ZrrJUrf8X9UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_model.fit(Etrain,trained,epoch = 4)"
      ],
      "metadata": {
        "_kg_hide-output": false,
        "_kg_hide-input": true,
        "trusted": true,
        "id": "atif5c6JX9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2_5C6BkjX9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########Creating test case#############\n",
        "Ntest = 100000\n",
        "test_data = random.sample(list(all_log_event),Ntest)\n",
        "test = []\n",
        "tr = bool(0)#anomaly or normal for every log data\n",
        "for i in test_data:\n",
        "    if(all_log_event[i] == 'normal'):\n",
        "        tr = 0;\n",
        "    else:\n",
        "        tr = 1;\n",
        "    test.append(tr)\n",
        "    tr = bool(0)\n",
        "# vectorize = Tokenizer(filters='1234567890')\n",
        "test_data = vectorize.texts_to_sequences(test_data)#replacing words with numbers\n",
        "\n",
        "Ttest =[]\n",
        "for i in test_data:\n",
        "    temp = []\n",
        "    for j in range(1,1+len(coded)):\n",
        "        if(j in i):\n",
        "            temp.append(TfIdf[j-1])\n",
        "        else:\n",
        "            temp.append(0)\n",
        "    Ttest.append(temp)"
      ],
      "metadata": {
        "trusted": true,
        "id": "LTMR1N3MX9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###creating a list of indices where there is anommaly\n",
        "my_list = np.array(test) \n",
        "indices = np.where(my_list == 1)[0]\n",
        "print(indices)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_DdJjTFtX9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####Creating a E test matrix############\n",
        "Etest = np.matmul(np.array(Ttest),np.array(newW))"
      ],
      "metadata": {
        "trusted": true,
        "id": "TMLWVbHoX9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####Predicting#######\n",
        "# ans = final_model.predict(Etest)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ri0DVcj9X9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######Calculating TP,TN, FP, FN and F1 score###########\n",
        "true_positive = 0\n",
        "true_negative = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "thre=0.01070902\n",
        "\n",
        "for count,i in enumerate(ans):\n",
        "    if i>=thre:#predicted anomaly or predicted neg\n",
        "        if(test[count] == 0):#actual normal\n",
        "            false_negative +=1\n",
        "        else:#actual abnormal\n",
        "            true_negative +=1\n",
        "    else:#predicted normal or precidicted pos\n",
        "        if(test[count] == 0):#actual normal\n",
        "            true_positive +=1\n",
        "        else:#actual abnormal\n",
        "            false_positive +=1       "
      ],
      "metadata": {
        "trusted": true,
        "id": "GT5PbcHxX9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########Evaluation of model###########\n",
        "print(true_positive,\" \", true_negative,\" \", false_positive,\" \",false_negative)\n",
        "precision = true_positive/(true_positive + false_positive)\n",
        "recall = true_positive/(true_positive + false_negative)\n",
        "\n",
        "print(precision,\" \",recall)\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "print(f1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VVeTEoV8X9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################"
      ],
      "metadata": {
        "trusted": true,
        "id": "A17akNBVX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/convolve-train/test.csv')\n",
        "test_data = list(df[' Log'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "NOY_w9b4X9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_data)"
      ],
      "metadata": {
        "trusted": true,
        "id": "i1MkWRf5X9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######Preprocessing Test Data############\n",
        "ptest_data = []\n",
        "j = 0\n",
        "for i in test_data:\n",
        "    temp=\"\"\n",
        "    for k in i.split()[8:]:\n",
        "        if(any(ch.isdigit() for ch in k) == False):\n",
        "            temp+=k\n",
        "            temp+=\" \"\n",
        "    ptest_data.append(temp)\n",
        "    j+=1\n",
        "test_data = ptest_data"
      ],
      "metadata": {
        "trusted": true,
        "id": "-mwUmVdoX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########Matrix T#############\n",
        "\n",
        "# vectorize = Tokenizer(filters='1234567890')\n",
        "test_data = vectorize.texts_to_sequences(test_data)#replacing words with numbers\n",
        "\n",
        "Ttest =[]\n",
        "for i in test_data:\n",
        "    temp = []\n",
        "    for j in range(1,1+len(coded)):\n",
        "        if(j in i):\n",
        "            temp.append(TfIdf[j-1])\n",
        "        else:\n",
        "            temp.append(0)\n",
        "    Ttest.append(temp)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dEhYQMhmX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####Creating a E test matrix############\n",
        "Etest = np.matmul(np.array(Ttest),np.array(newW))"
      ],
      "metadata": {
        "trusted": true,
        "id": "gHx54Z0uX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####Predicting#######\n",
        "ans = final_model.predict(Etest)"
      ],
      "metadata": {
        "trusted": true,
        "id": "TZekR0I9X9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######binary classification######\n",
        "bans = []\n",
        "for i in ans:\n",
        "    if i>=thre:#predicted anomaly or predicted neg\n",
        "        bans.append(\"abnormal\" )\n",
        "    else:#predicted normal or precidicted pos\n",
        "        bans.append(\"normal\")    "
      ],
      "metadata": {
        "trusted": true,
        "id": "h27NoF8aX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = {'ID':list(df['ID']),' Label':bans}\n",
        "df = pd.DataFrame(submission)"
      ],
      "metadata": {
        "trusted": true,
        "id": "odjHUVdyX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "trusted": true,
        "id": "T1XRQKHnX9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('sub2.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MhNqqzhNX9Ub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}